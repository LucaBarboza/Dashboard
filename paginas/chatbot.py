import streamlit as st
import google.generativeai as genai

# --- CONFIGURA√á√ÉO DA P√ÅGINA ---
st.header("ü§ñ Assistente T√©cnico do Projeto")
st.markdown("""
Este assistente √© o **especialista na metodologia** deste trabalho. 
Voc√™ pode perguntar sobre as escolhas estat√≠sticas, as bibliotecas utilizadas ou como os algoritmos de Machine Learning foram configurados.
""")

# --- 1. CONFIGURA√á√ÉO DA API ---
# Tenta pegar do secrets (nuvem) ou pede na sidebar (local)
api_key = st.sidebar.text_input("Gemini API Key:", type="password")

# Se estiver rodando localmente sem secrets, use a input. Se tiver secrets, usa direto.
if not api_key:
    if "GEMINI_KEY" in st.secrets:
        api_key = st.secrets["GEMINI_KEY"]
    else:
        st.warning("‚ö†Ô∏è Insira a chave da API do Google Gemini na barra lateral para come√ßar.")
        st.stop()

try:
    genai.configure(api_key=api_key)
    # Usando o modelo Flash (R√°pido e Inteligente)
    model = genai.GenerativeModel('gemini-2.5-flash') 
except Exception as e:
    st.error(f"Erro de Configura√ß√£o: {e}")
    st.stop()

# --- 2. O "C√âREBRO" DO BOT (Documenta√ß√£o T√©cnica Est√°tica) ---
# Este contexto √© "blindado". Ele s√≥ sabe o que est√° escrito aqui, evitando alucina√ß√µes.
CONTEXTO_DO_PROJETO = """
VOC√ä √â O ASSISTENTE T√âCNICO DE UM DASHBOARD DE AN√ÅLISE CLIM√ÅTICA (BRASIL 2015-2021).
Sua fun√ß√£o √© explicar a metodologia cient√≠fica e t√©cnica usada no trabalho.

AQUI EST√Å A DOCUMENTA√á√ÉO T√âCNICA:

1. DADOS:
- Fonte: INMET (Instituto Nacional de Meteorologia) via Kaggle.
- Per√≠odo: 2015 a 2021.
- Granularidade: Semanal.
- Tratamento: Limpeza de dados nulos e engenharia de recursos (cria√ß√£o de colunas Ano/M√™s/Esta√ß√£o).

2. ARQUITETURA DE SOFTWARE:
- Linguagem: Python.
- Interface: Streamlit.
- Visualiza√ß√£o: Plotly Express (para interatividade).
- Cache: Usamos `@st.cache_data` para otimizar o carregamento.

3. P√ÅGINA: MAPA TEMPORAL (GEOESPACIAL):
- Tecnologia: Mapa Coropl√©tico animado (`animation_frame`).
- Decis√£o de Design: Fixamos o `range_color` (escala de cores) com o m√≠nimo e m√°ximo global dos dados. 
  - Por que? Para garantir que a cor "Vermelho Escuro" represente a mesma temperatura em 2015 e 2021, permitindo compara√ß√£o visual justa.

4. P√ÅGINA: ESTAT√çSTICA (CORRELA√á√ÉO):
- Exibimos matrizes de Pearson (Linear) e Spearman (N√£o-Linear/Postos) lado a lado para identificar rela√ß√µes complexas entre vari√°veis (ex: Chuva x Temperatura).

5. P√ÅGINA: TESTE DE HIP√ìTESES (RIGOR CIENT√çFICO):
- O sistema possui um algoritmo de decis√£o autom√°tica:
  1. Roda Shapiro-Wilk (Teste de Normalidade).
  2. Roda Levene (Teste de Homogeneidade de Vari√¢ncia).
  3. DECIS√ÉO:
     - Se Normal + Homog√™neo -> Aplica ANOVA One-Way (ou Teste T).
     - Se Normal + Heterog√™neo -> Aplica Teste T de Welch.
     - Se N√£o-Normal -> Aplica Kruskal-Wallis (ou Mann-Whitney U).
- Independ√™ncia: Alertamos o usu√°rio que dados semanais possuem autocorrela√ß√£o, sugerindo o uso de "M√©dias Anuais" para valida√ß√£o estat√≠stica robusta.

6. P√ÅGINA: MODELAGEM (MACHINE LEARNING):
- Clusteriza√ß√£o: Usamos K-Means para agrupar estados por similaridade clim√°tica, ignorando fronteiras pol√≠ticas.
- Detec√ß√£o de Anomalias: Usamos Isolation Forest para encontrar semanas com comportamento clim√°tico extremo (outliers).
- Previs√£o (S√©ries Temporais):
  - Modelo: Regress√£o Linear M√∫ltipla.
  - T√©cnica: Criamos "Dummy Variables" para os meses (One-Hot Encoding).
  - Motivo: Isso permite que um modelo linear aprenda a curva sazonal (ondas de calor e frio) ao longo do ano.
  - Valida√ß√£o: Backtesting (treino no passado, teste no ano mais recente).

DIRETRIZES DE RESPOSTA:
- Responda apenas sobre a metodologia, ferramentas e conceitos acima.
- Se perguntarem sobre um dado espec√≠fico (ex: "Qual a temperatura dia 15?"), diga: "Eu sou focado na metodologia do projeto. Para explorar os dados brutos, por favor utilize a aba 'Dashboard Interativo' ou 'Mapa'."
- Seja formal e acad√™mico.
"""

# --- 3. GERENCIAMENTO DO CHAT ---
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
    # Inicia o chat enviando o manual (invis√≠vel ao usu√°rio)
    st.session_state.chat = model.start_chat(history=[
        {"role": "user", "parts": CONTEXTO_DO_PROJETO},
        {"role": "model", "parts": "Entendido. Atuarei como o especialista t√©cnico do projeto."}
    ])

# Exibe hist√≥rico visual
for msg in st.session_state.chat_history:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# Input do usu√°rio
if prompt := st.chat_input("D√∫vidas sobre a metodologia? (Ex: Como funciona o teste de hip√≥tese?)"):
    # Mostra mensagem do usu√°rio
    with st.chat_message("user"):
        st.markdown(prompt)
    st.session_state.chat_history.append({"role": "user", "content": prompt})

    # Gera resposta
    with st.chat_message("assistant"):
        with st.spinner("Consultando documenta√ß√£o t√©cnica..."):
            try:
                response = st.session_state.chat.send_message(prompt)
                st.markdown(response.text)
                st.session_state.chat_history.append({"role": "assistant", "content": response.text})
            except Exception as e:
                st.error(f"Erro ao gerar resposta: {e}")
